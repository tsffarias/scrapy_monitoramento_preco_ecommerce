# Projeto de ETL para Monitoramento de PreÃ§os e Produtos E-commerce

## DescriÃ§Ã£o

Imagine que uma marca de tÃªnis deseja avaliar sua relevÃ¢ncia no ecossistema do Mercado Livre, Amazon, Magalu, Shopee e Centauro. Para isso, Ã© necessÃ¡rio obter **KPIs** relacionados ao segmento de tÃªnis nessas plataformas. O objetivo Ã© coletar informaÃ§Ãµes detalhadas e implementar um dashboard que facilite a visualizaÃ§Ã£o e anÃ¡lise desses dados.

## Proposta do Projeto

Fomos contratados por uma grande empresa para fazer uma pesquisa de mercado na categoria de tÃªnis esportivos dentro de diversos e-commerces: Mercado Livre, Amazon, Magalu, Shopee, Centauro. O objetivo dessa empresa Ã© avaliar:
- ğŸ‘Ÿ Quais marcas sÃ£o mais encontradas atÃ© a 10Âª pÃ¡gina
- ğŸ’° Qual o preÃ§o mÃ©dio por marca
- â­ Qual a satisfaÃ§Ã£o por marca

## Etapas do Projeto

### Etapa 1: ExtraÃ§Ã£o dos Dados
UtilizaÃ§Ã£o de **Web Scraping** com a biblioteca **Scrapy** para obter os dados necessÃ¡rios do Mercado Livre, Amazon, Magalu, Shopee, Centauro.

### Etapa 2: TransformaÃ§Ã£o dos Dados
Processamento e limpeza dos dados utilizando a biblioteca **Pandas** para garantir que estejam prontos para anÃ¡lise.

### Etapa 3: Carregamento dos Dados
Armazenamento dos dados transformados em um banco de dados **SQLite3**.

### Etapa 4: VisualizaÃ§Ã£o dos Dados
Desenvolvimento de um **dashboard interativo** usando **Streamlit** para consumir os dados e apresentar os insights de forma visual e intuitiva.

## Ferramentas Utilizadas

- **Python**: Linguagem de programaÃ§Ã£o utilizada para o desenvolvimento do projeto.
- **Pandas**: Biblioteca utilizada para manipulaÃ§Ã£o e transformaÃ§Ã£o de dados.
- **Scrapy**: Framework utilizado para realizar o web scraping e extrair dados da web.
- **Streamlit**: Framework utilizado para criar aplicaÃ§Ãµes web interativas e visualizar os dados extraÃ­dos.
- **SQLite3**: Banco de dados utilizado para armazenar os dados transformados.

## Estrutura de DiretÃ³rios

```plaintext
.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ data.json
â”‚   â””â”€â”€ quotes.db
src/
â”œâ”€â”€ coleta/
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â””â”€â”€ preco_spider.py
â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”œâ”€â”€ items.py
â”‚   â”œâ”€â”€ settings.py
â”œâ”€â”€ transformacao/
â”‚   â”œâ”€â”€ transform.py
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Como Executar o Projeto

Primeiramente, acesse a pasta do projeto e instale as dependÃªncias usando o `pip` ou o `Poetry`. Para isso, execute um dos comandos abaixo:

```sh
poetry install
```

ou

```sh
pip install -r requirements.txt
```

Em seguida, para executar cada etapa, siga as instruÃ§Ãµes abaixo:

### ExtraÃ§Ã£o dos dados usando Web Scraping

```sh
cd src/coleta/
scrapy crawl mercadolivre -o ../../data/mercado_livre.jsonl
```

### Transformar e carregar os dados

```sh
python src/transformacao/mercado_livre.py
```

### Visualizar Dashboard

```sh
streamlit run dashboard/app.py
```